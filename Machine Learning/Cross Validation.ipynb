{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99566472-5250-40c9-9115-6994896aa697",
   "metadata": {},
   "source": [
    "## Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c07ad52-17cd-488c-b4a8-5cb906a1f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import neccesary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for visualization \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2b8c0d-245b-4853-9528-5a6bddd684a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets read the Data \n",
    "df=pd.read_csv(\"https://raw.githubusercontent.com/s4sauravv/Datasets/main/breast%20cancer.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f0cc08-43af-40bf-b311-c0bfa06d1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Summazrize the data\n",
    "df.shape\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509247df-089e-455f-8536-703febccd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 32','id'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c7f204-1afc-45e0-92a8-d7101c119afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eebb470b-3d8a-49c6-b129-05aa6db0fbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Check our Label\n",
    "df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1777e06f-1058-4fb3-b55a-fdceb9f7b756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets  plot the  diagnosis in countplot\n",
    "\n",
    "sns.countplot(x='diagnosis',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6d0d02-7cf9-4c69-bbe2-47e4738eb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis']=df['diagnosis'].replace({'M':0,'B':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287ab78c-c677-4f00-aff2-513b73edfe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now This Time Select Best Feature out of 31  We use new tecniques lets see SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740dd10d-03e6-4527-92c6-573c0a67a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('diagnosis',axis=1)\n",
    "y=df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9ba9d7-a63f-4830-a901-b74b2c3f7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e185120-bc10-4eba-ade7-d8cc8bb1294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature       Score\n",
      "27  concave points_worst  964.385393\n",
      "22       perimeter_worst  897.944219\n",
      "7    concave points_mean  861.676020\n",
      "20          radius_worst  860.781707\n",
      "2         perimeter_mean  697.235272\n",
      "23            area_worst  661.600206\n",
      "0            radius_mean  646.981021\n",
      "3              area_mean  573.060747\n",
      "6         concavity_mean  533.793126\n",
      "26       concavity_worst  436.691939\n",
      "5       compactness_mean  313.233079\n",
      "25     compactness_worst  304.341063\n",
      "10             radius_se  268.840327\n",
      "12          perimeter_se  253.897392\n"
     ]
    }
   ],
   "source": [
    "select_feature=SelectKBest(score_func=f_classif,k=14)\n",
    "fit=select_feature.fit(x,y)\n",
    "score=pd.DataFrame(fit.scores_)\n",
    "column=pd.DataFrame(x.columns)\n",
    "\n",
    "best_feature=pd.concat([column,score],axis=1)\n",
    "best_feature.columns=['Feature','Score']\n",
    "print(best_feature.nlargest(14,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4513022-b20f-449c-b1e9-3c71405fb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df[['concave points_worst','perimeter_worst','concave points_mean','radius_worst','perimeter_mean','area_worst','radius_mean','area_mean','concavity_mean','concavity_worst','compactness_mean','compactness_worst','radius_se','perimeter_se']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f6e6c4-efcb-445e-8a68-d53d20cdc9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2654</td>\n",
       "      <td>184.60</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>25.380</td>\n",
       "      <td>122.80</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>8.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1860</td>\n",
       "      <td>158.80</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>24.990</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>3.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2430</td>\n",
       "      <td>152.50</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>23.570</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>4.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2575</td>\n",
       "      <td>98.87</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>14.910</td>\n",
       "      <td>77.58</td>\n",
       "      <td>567.7</td>\n",
       "      <td>11.42</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>3.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1625</td>\n",
       "      <td>152.20</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>22.540</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>5.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.2216</td>\n",
       "      <td>166.10</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>25.450</td>\n",
       "      <td>142.00</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>21.56</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>7.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.1628</td>\n",
       "      <td>155.00</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>23.690</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>20.13</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>5.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.1418</td>\n",
       "      <td>126.70</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>18.980</td>\n",
       "      <td>108.30</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>3.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.2650</td>\n",
       "      <td>184.60</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>25.740</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>20.60</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>5.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>59.16</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.456</td>\n",
       "      <td>47.92</td>\n",
       "      <td>268.6</td>\n",
       "      <td>7.76</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>2.548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     concave points_worst  perimeter_worst  concave points_mean  radius_worst  \\\n",
       "0                  0.2654           184.60              0.14710        25.380   \n",
       "1                  0.1860           158.80              0.07017        24.990   \n",
       "2                  0.2430           152.50              0.12790        23.570   \n",
       "3                  0.2575            98.87              0.10520        14.910   \n",
       "4                  0.1625           152.20              0.10430        22.540   \n",
       "..                    ...              ...                  ...           ...   \n",
       "564                0.2216           166.10              0.13890        25.450   \n",
       "565                0.1628           155.00              0.09791        23.690   \n",
       "566                0.1418           126.70              0.05302        18.980   \n",
       "567                0.2650           184.60              0.15200        25.740   \n",
       "568                0.0000            59.16              0.00000         9.456   \n",
       "\n",
       "     perimeter_mean  area_worst  radius_mean  area_mean  concavity_mean  \\\n",
       "0            122.80      2019.0        17.99     1001.0         0.30010   \n",
       "1            132.90      1956.0        20.57     1326.0         0.08690   \n",
       "2            130.00      1709.0        19.69     1203.0         0.19740   \n",
       "3             77.58       567.7        11.42      386.1         0.24140   \n",
       "4            135.10      1575.0        20.29     1297.0         0.19800   \n",
       "..              ...         ...          ...        ...             ...   \n",
       "564          142.00      2027.0        21.56     1479.0         0.24390   \n",
       "565          131.20      1731.0        20.13     1261.0         0.14400   \n",
       "566          108.30      1124.0        16.60      858.1         0.09251   \n",
       "567          140.10      1821.0        20.60     1265.0         0.35140   \n",
       "568           47.92       268.6         7.76      181.0         0.00000   \n",
       "\n",
       "     concavity_worst  compactness_mean  compactness_worst  radius_se  \\\n",
       "0             0.7119           0.27760            0.66560     1.0950   \n",
       "1             0.2416           0.07864            0.18660     0.5435   \n",
       "2             0.4504           0.15990            0.42450     0.7456   \n",
       "3             0.6869           0.28390            0.86630     0.4956   \n",
       "4             0.4000           0.13280            0.20500     0.7572   \n",
       "..               ...               ...                ...        ...   \n",
       "564           0.4107           0.11590            0.21130     1.1760   \n",
       "565           0.3215           0.10340            0.19220     0.7655   \n",
       "566           0.3403           0.10230            0.30940     0.4564   \n",
       "567           0.9387           0.27700            0.86810     0.7260   \n",
       "568           0.0000           0.04362            0.06444     0.3857   \n",
       "\n",
       "     perimeter_se  \n",
       "0           8.589  \n",
       "1           3.398  \n",
       "2           4.585  \n",
       "3           3.445  \n",
       "4           5.438  \n",
       "..            ...  \n",
       "564         7.673  \n",
       "565         5.203  \n",
       "566         3.425  \n",
       "567         5.772  \n",
       "568         2.548  \n",
       "\n",
       "[569 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a842ced-e7d6-434b-a64e-e66b0586aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b268378e-6ad8-4bc4-838a-857e407c8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c175412a-e7e2-4c9c-805d-9653e2c7686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler=scaler.fit_transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78cb1ca3-135a-448e-a17b-29a37350396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_scaler,y,test_size=0.25,random_state=94255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd9271e-2a5e-48ce-93d8-a14d578c67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets make one function and use every time for checking test score and train score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a7fffc6-7e2a-43d1-a2aa-c05033ce0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_score(clf,x_train,x_test,y_train,y_test,train=True):\n",
    "    if train:\n",
    "        y_pred=clf.predict(x_train)\n",
    "        print('=============== Train Test===============')\n",
    "        print(f\"Accuracy Score :{accuracy_score(y_train,y_pred)*100:.2f}%\")\n",
    "    elif train==False:\n",
    "        pred=clf.predict(x_test)\n",
    "        print(\"===================Train Test============\")\n",
    "        print(f\"Accuracy Score :{accuracy_score(y_test,pred)*100:.2f}%\")\n",
    "        \n",
    "        \n",
    "        print(\"Classification Report \",classification_report(y_test,pred,digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "486ff76f-4796-4ec3-8688-21a8caaba4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e770e7ff-6ab7-4abb-b2ed-9ad84e09bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b5b6584-849f-4d3c-b9cd-995c5a77f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Train Test===============\n",
      "Accuracy Score :95.31%\n"
     ]
    }
   ],
   "source": [
    "metric_score(knn,x_train,x_test,y_train,y_test,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e68042bb-7c5f-42df-b7c4-bd1b9c64803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check For test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46ec1761-8485-4ee4-b27b-23c6a624ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Train Test============\n",
      "Accuracy Score :93.71%\n",
      "Classification Report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        55\n",
      "           1       0.94      0.95      0.95        88\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_score(knn,x_train,x_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d312a3-ee85-434b-a5b0-37d5d4fdf5d5",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Cross Validation is a technique . Suppose you train a model on a given dataset. Using any specific algorithm . you tried to find the accuracy of the trained model using the same training data and found the accuracy of the trained model using the same training data and found the accuracy to be 95 % or maybe 100% . what does this mean ? Is your model ready for prediction ? The answer is no . Why? Because Your Model has trained itself on the given data . i.e it knows the data it has generalised over a new set of data , its most likely to give you very bad accuracy, beacause it has never seen the data before and thus it falls to generalizes well over it . This is the problem of overfitting . to tackle such problem , cross_validation comes into a picture .\n",
    "\n",
    "Cross Validation is a resampling technique with a basic idea of dividing the training dataset into two parts. i.e train and test on one part(train) your try to train the model and on the second part (test) i.e the data which is unseen for the model , you make the predictionand check how well your model works on it. if the model works with good accuracy your test data it means that the model has not overfitted the training data and can be trusted with the prediction, wheareas if it performs with bad accuracy our modelis not to be trusted and we need to tweak our algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8210a74-e585-4fe7-aeaf-dff3643b298f",
   "metadata": {},
   "source": [
    "## Defination - \n",
    "There are some data points so these Red color also present in the test data . so that time there is a possibility your model is overfitted beacuse model has already seen here. this red data and some data exist in is test set . possibility you get 95% ,93% sometime 100% also, So that time how can we avoind such kind of situation,\n",
    "\n",
    "## Q- How can we build Generalised Model ?\n",
    "\n",
    "Generalised Model - Generalised Model means it should change be in a position generalise the data . Means to avoid overfiting and overcoming of this overfitting and building a model that is generalised model which means model is not overfitted neither underfitted.\n",
    "\n",
    "## Q - How to tackle such situation ?\n",
    "\n",
    "1-Hold Out Method - Hold Out method is nothing is a train test split\n",
    "2 - K-Fold - Cross_ Validation - It is better then train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4173a9-bc28-4cf8-b755-5bfe7ea2bc60",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation - So the problem with a hold out method if sample are same in both train test your model will over fit ...\n",
    "\n",
    "How To avoid this kind of a situation ?\n",
    "\n",
    "So thats were k fold cross validation comes into a picture .. Lets say whenever i say cross validation = 5 , we have to tell how many iteration and folds K means --> How many fold there is 5 Fold.\n",
    "\n",
    "How its Work ?\n",
    "\n",
    "This dataset trained 5 times . and within iteration 1 in that this whole dataset .it is going to split in 5 pieces / 5 sets (5 iteration/5split) it will divide in equal parts suppose there is a total 100% means 80% of the data kept for model training and 20 % will be use for testing.\n",
    "\n",
    "Similarly 2nd iteration will take second part of the iteration for testing and left 5 part is use for training . similary its happen to all iteration. it depend on how much you give cross validation .\n",
    "\n",
    "--> It means every iteration our testing data is going to be different and our training data is also changing partially.\n",
    "\n",
    "Then after testing we are going to find accuracy of each training and test data set and we claculate the mean of all set of iteration.\n",
    "\n",
    "Q- Why we are not using this every time ?\n",
    "\n",
    "We will have 1 training set and 1 testing set . in order to train this . let suppose its taking 5 hours (litrelly it takes) in order to train the huge amount of data . it takes training time it need to identify all the patterns it has to study . if there are more numbers of feature we are adding so much data to it . it takes more time.\n",
    "\n",
    "in this k-fold cross validation we need to check number of times how much we enter CV value.\n",
    "\n",
    "Suppose we enter 5 CV then suppose 5 hr take to read one set of data then you imagine then how many time we burn.\n",
    "\n",
    "1 Hour Cost = 10$\n",
    "\n",
    "Q - One more Question if you are rich . then i think you dont mind in spending 250 $? agree?\n",
    "\n",
    "Will you buy time , will you buy 25 hours and we dont train only one time means when you are working on a preoject there are situation you have to keep changing a data keep trying if you are not satified with the numbers again you have to retrain.\n",
    "\n",
    "--> To tackle the high variance of hold out method , the k-fold method is used . the idea is simple , divide the whole dataset into 'K' sets preferably of equal size . then the first set is selected as the test set and the rest (K-1) sets are used to train the data . error is calculated for this particular dataset .then the steps are repeated .i.e the second set is selectionas the test data and the remaining (k-1) sets are used as the training data Again , the error is calculated similarly , the preocess continious for 'K' times . In the end , the cv error is given as the mean of the total errors calculated individually . Mathematically given as :-\n",
    "\n",
    "The variance in error decreases with the increase in 'K' . The advantage of k-fold CV is that it is computationally expensive as the algorithm runs from scratch for 'K' times\n",
    "\n",
    "## Leave one Out Cross Validation (LOOCV)\n",
    "\n",
    "Let say you have 100 records , so what 100 cv does . so 99 records will be used for training and starting one record will be use for testing and 2nd iteration second will be used for testing and reamaining 99 wil used for training . similarly it execute 100 times and every time it will produce accuracy thenw e are going to take average.\n",
    "\n",
    "Similarly as k fold in the k fold we will group the data we sill split into sets . depending on upon hou many numbers we are going to mention but loocv numbers of records number of training.\n",
    "\n",
    "So know you are imagine how costly they going to be ..Accuracy wise its awsome but who have time very very rare uses of this because time and money.\n",
    "\n",
    "LOOCV - Is a speacial case of K Fold CV . Where k becomes equal to n (number of observation) So instead of creating two subset . it selects a single observation as a test data a rest of data as the training dat . The error is calculated for this test observation Now the second observation is selected as test data and the rest of the data is used as the training set . again the error is calculated for this particular test observation this process continues 'n' times and in the end , cv error is calulated as ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65ccbd62-a4f9-4277-9970-4ed938696870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kfold method (for demo purpose only). you dont need to practice this.\n",
    "from sklearn.model_selection import KFold,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03d4e0bf-a524-4ae0-bd67-3f62806dfcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_f=KFold(n_splits=3)\n",
    "k_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50954c8-24a7-47cb-8fc2-b21b645fa395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  [3 4 5 6 7 8] test  [0 1 2]\n",
      "train  [0 1 2 6 7 8] test  [3 4 5]\n",
      "train  [0 1 2 3 4 5] test  [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for train,test in k_f.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print('train ',train,'test ',test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f03c2c-2593-4d03-a480-02270ec8f3be",
   "metadata": {},
   "source": [
    "## Cross Validation score to check if the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3adaf87-d62b-40c0-8070-5deb8d3d5c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9122807 , 0.92105263, 0.96491228, 0.93859649, 0.94690265])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn,x_scaler,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baaa03f4-b36f-466c-92e8-66a7ef6ba011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9367489520260829"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(KNeighborsClassifier(),x_scaler,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34111c-a978-4adb-b2bb-9729eba9ee7b",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning :\n",
    "What is hyperparameter tuning ?\n",
    "\n",
    "Just look the picture in above picture . what tell this picture to us . Just understand this points suppose we are listning a radio the one which has a nob , not the electronic.\n",
    "\n",
    "So you are trying to listen songs and one situation is playing good song and you are not able to hear it properly . so you are trying to adjust your knob turn, right , left, slowly some time fast . untill you get there is no noise in the music . the knob you are going to tune it . why are adjusting to listen quality sound.\n",
    "\n",
    "Similarly we going to adjust our parameter.\n",
    "\n",
    "Q- What are those parameter ? i need to change some parameter , some of the internel things that model is assuming and building the model . by default value it will take and build and it will run.\n",
    "\n",
    "i wanted to change the default values like .\n",
    "\n",
    "K=3\n",
    "\n",
    "K=5\n",
    "\n",
    "We dont know 3 is best or 5 is best we dont know which k values is best it is taking which ever it wants to take and execute it and train it .\n",
    "\n",
    "Not i wanted to change that number so that may be increase the accuracy . so that is what tuning here.\n",
    "\n",
    "What are you tuning -- The parameter\n",
    "\n",
    "What are the parametere - Every algorithm has different parameter .\n",
    "\n",
    "Maximum time it will increase the accuracy.\n",
    "\n",
    "There are two popular Hyperparameter tuning\n",
    "\n",
    "1- GridSearchCV\n",
    "\n",
    "2-RandomSearchCV\n",
    "\n",
    "This are the technique we used to tune the parameter.\n",
    "\n",
    "## Lets Use Grid Function for the best parameter to imporve the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b7475-5bf4-4621-afad-7d0e04626e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a269391-f682-4b45-9680-9bbdb2828b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4506a-e7c2-4e24-a269-06fd5c8a428a",
   "metadata": {},
   "source": [
    "Before that we have to know something.\n",
    "\n",
    "KNN is also called brute force Method\n",
    "\n",
    "KD Tree - We dont use most of the time .\n",
    "\n",
    "Ball Tree - We dont use the most of time time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3592b4af-f63c-4777-a332-b7628a1f34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'crityerian':['entropy','gioni'],\n",
    "            'min_leaf_size':[3,5,6,7,8],\n",
    "            'n_neighbors':[3,5,7,9,11,13]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b1f5652-1a6e-432b-827d-cc7313a220a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch=GridSearchCV(estimator=knn,param_grid=param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf86231-c1b0-4d67-9c40-3ff98027bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67f0cab9-58db-40a8-aaa7-d6d02f9ebd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crityerian': ['entropy', 'gioni'],\n",
       " 'min_leaf_size': [3, 5, 6, 7, 8],\n",
       " 'n_neighbors': [3, 5, 7, 9, 11, 13]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62897b14-256c-4274-a6c2-342d74779bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(algorithm=&#x27;kd_tree&#x27;, leaf_size=3, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;kd_tree&#x27;, leaf_size=3, n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=3, n_neighbors=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We wil use the best paramaeter in our K-NN algorithm and check if accuracy is increasing .\n",
    "\n",
    "knn=KNeighborsClassifier(algorithm='kd_tree',leaf_size=3,n_neighbors=3)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4a37935-a272-46ea-ba85-bda2b35e449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Train Test===============\n",
      "Accuracy Score :96.24%\n",
      "===================Train Test============\n",
      "Accuracy Score :90.91%\n",
      "Classification Report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88        55\n",
      "           1       0.92      0.93      0.93        88\n",
      "\n",
      "    accuracy                           0.91       143\n",
      "   macro avg       0.91      0.90      0.90       143\n",
      "weighted avg       0.91      0.91      0.91       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Call the function and pass datset to check train ad test score\n",
    "metric_score(knn,x_train,x_test,y_train,y_test,train=True)\n",
    "metric_score(knn,x_train,x_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8ce0266-32cb-45c7-9917-53d6bcfaf66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  7],\n",
       "       [ 6, 82]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you want to check confusion matrix you can check.\n",
    "\n",
    "y_pred=knn.predict(x_test)#we are predicting once again because variable inside the fucntion are local varibale.\n",
    "cfm=confusion_matrix(y_test,y_pred)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cff6b9-5765-44d5-b586-f66fa13076f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
