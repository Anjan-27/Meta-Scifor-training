{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0eHZwAuL_1s",
    "outputId": "610cef89-1d5c-4c36-8c34-dfd3cac0a449"
   },
   "source": [
    "## What is spaCy?\n",
    "Spacy is an open-source, free Python module for sophisticated natural language processing (NLP).\n",
    "\n",
    "You'll eventually want to know more about the text you're working with, let's say. For instance, what's the matter? In the context, what do the words mean? What is being done to whom by whom? Which goods and businesses are referenced in the text? Which texts are comparable to one another?\n",
    "\n",
    "Spicy, which was created especially for production use, aids in the development of applications that can handle and \"understand\" vast amounts of text. It can be used to pre-process text for deep learning or to create systems for information extraction or natural language processing.\n",
    "\n",
    "## What isn't spacy?\n",
    "First, spaCy isn't a platform or an \"API\". \n",
    "Second, spaCy is not an out-of-the-box chat bot engine. \n",
    "Third, spaCy is not research software. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical models\n",
    "Some of spaCy's features work independently, while others require statistical models to be loaded, which enable spaCy to predict linguistic annotations. For example, whether a word is a verb or noun. spaCy currently offers statistical models for a variety of languages, which can be installed as individual Python modules. Models can differ in size, speed, memory usage, accuracy, and the data they include. The model you choose always depends on your use cases and the texts you're working with. For a general use case, the small and the default models are always a good start. They typically include the following components:\n",
    "\n",
    "Binary weights for the part-of-speech tagger, dependency parser, and named entity recognizer to predict those annotations in context.\n",
    "\n",
    "Lexical entries in the vocabulary, i.e. words and their context-independent attributes like the shape or spelling.\n",
    "\n",
    "Data files like lemmatization rules and lookup tables.\n",
    "\n",
    "Word vectors, i.e. multi-dimensional meaning representations of words that let you determine how similar they are to each other.\n",
    "Configuration options, like the language and processing pipeline settings, to put spaCy in the correct state when you load in the model.\n",
    "\n",
    "## Linguistic annotations\n",
    "A spacy offers a range of linguistic annotations to help you understand the grammatical structure of a text. This covers the many kinds of words, such as the parts of speech, and the relationships between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## install spacy with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2pbgyPdzM7CJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\gill\\python\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (67.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\gill\\python\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\gill\\python\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gill\\python\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\gill\\python\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\gill\\python\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gill\\python\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gill\\python\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gill\\python\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gill\\python\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in c:\\users\\gill\\python\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\gill\\python\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\gill\\python\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\gill\\python\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\gill\\python\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\gill\\python\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\gill\\python\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\gill\\python\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gill\\python\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\gill\\python\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gill\\python\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gill\\python\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gill\\python\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gill\\python\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 11.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.6/12.8 MB 13.0 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 10.0/12.8 MB 13.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxay9zu7MPF3",
    "outputId": "1047ca32-0748-40e6-83e5-960d1e5b9ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN nsubj\n",
      "startup VERB ccomp\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n",
    "# Text: The original word text.\n",
    "# Lemma: The base form of the word.\n",
    "# POS: The simple part-of-speech tag.\n",
    "# Tag: The detailed part-of-speech tag.\n",
    "# Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "# Shape: The word shape - capitalization, punctuation, digits.\n",
    "# is alpha: Is the token an alpha character?\n",
    "# is stop: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "During processing, spaCy first tokenizes the text, i.e., segments it into words, punctuation, and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off—whereas \"U.K.\" should remain one token. Each Doc consists of individual tokens, and we can iterate over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VA0EsipWMyDa",
    "outputId": "8b49c93b-2244-496e-e61c-4081ce5c62f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech(pos) tags and dependencies\n",
    "After tokenization, spaCy can parse and tag a given Doc. This is where the statistical model comes in, which enables spaCy to make a prediction of which tag or label most likely applies in this context. A model consists of binary data and is produced by showing a system enough examples for it to make predictions that generalize across the language – for example, a word following \"the\" in English is most likely a noun.\n",
    "Tokens for linguistic annotations are available.Spacy, like many other NLP libraries, converts all strings to hash values in order to increase efficiency and minimize memory usage. Therefore, we must append an underscore__ to an attribute's name in order to obtain its readable string representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rp1hFZ37M8ii",
    "outputId": "620e1960-b30b-4f61-e3c3-6b1a42517af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus PROPN nsubj Coronavirus Xxxxx NNP True False\n",
      ": PUNCT punct : : : False False\n",
      "Delhi PROPN compound Delhi Xxxxx NNP True False\n",
      "resident NOUN nsubj resident xxxx NN True False\n",
      "tests VERB appos test xxxx VBZ True False\n",
      "positive ADJ amod positive xxxx JJ True False\n",
      "for ADP prep for xxx IN True True\n",
      "coronavirus NOUN pobj coronavirus xxxx NN True False\n",
      ", PUNCT punct , , , False False\n",
      "total ADJ ROOT total xxxx JJ True False\n",
      "31 NUM nummod 31 dd CD False False\n",
      "people NOUN dobj people xxxx NNS True False\n",
      "infected VERB acl infect xxxx VBN True False\n",
      "in ADP prep in xx IN True True\n",
      "India PROPN pobj India Xxxxx NNP True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_ , token.lemma_, token.shape_, token.tag_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "tqMjNwYyN5J5",
    "outputId": "d57812e8-1960-4c3f-f72f-0b6c680c146d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"10a98e30c7f148c4bfb1e5ecd7d5a334-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Google,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">crack</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">down</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">fake</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">coronavirus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">apps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-10a98e30c7f148c4bfb1e5ecd7d5a334-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Google, Apple crack down on fake coronavirus apps\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entities\n",
    "A named entity is a \"real-world object\" that has been given a name, such as a person, a nation, a product, or the title of a book. By requesting a prediction from the model, Spicy is able to identify different kinds of named entities in a document. This doesn't always work flawlessly and may require some fine-tuning later, depending on your use case, because models are statistical and heavily rely on the samples they were trained on. Named entities are accessible as a document's ents property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elo5HelaOdAY",
    "outputId": "a4f7f5ee-ab79-49ea-cfe6-b43a0646fac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 66 68 CARDINAL\n",
      "India 88 93 GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "L8if1eMBO1rS",
    "outputId": "61cec0b4-4905-478e-b3e1-c62e7fd74565"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: Delhi resident tests positive for coronavirus, total \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    31\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " people infected in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text =\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\"\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Vector and similarity\n",
    "A word's multi-dimensional meaning representations, known as \"word embeddings\" or word vectors, are compared to determine similarity.Word vectors typically look like this and can be created with an algorithm like word2vec:\n",
    "\n",
    "Important_note: Spacy's tiny models (all of the packages end in sm) only feature context-sensitive tensors and do not come with word vectors in order to keep them quick and simple. This implies that although you can still compare documents, tokens, and spans using similarity(), the results will be less satisfactory because each token will not have any assigned vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHTFJqyFPGu2",
    "outputId": "ca2610c1-e349-4843-a76d-a08682dce832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLsCxAMLPpRR",
    "outputId": "323205aa-dd8d-4b25-e0f3-967f7e3dbe38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion True 6.254689 True\n",
      "bear True 6.0756683 True\n",
      "apple True 6.385152 True\n",
      "banana True 6.4799643 True\n",
      "fadsfdshds True 7.043507 True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokens = nlp(\"lion bear apple banana fadsfdshds\")\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to their widespread usage in English, the terms \"lion,\" \"bear,\" \"apple,\" and \"banana\" are included in the model's lexicon and have accompanying vectors. The vector representation of the word \"fadsfdshds\" is 300 dimensions of 0, meaning it is almost nonexistent because it is far less common and out of lexicon. Consider using one of the larger models or loading in a whole vector package, such as en_vectors_web_Ig, which has more than a million unique vectors, if your application will benefit from a wider vocabulary with more vectors.\n",
    "\n",
    "The similarity() method included with each Doc, Span, and Token allows you to compare it to another object and calculate how similar they are. Naturally, the degree of similarity between \"dog\" and \"cat\" is always subjective; it truly relies on your point of view. A somewhat universal definition of similarity is typically assumed by spaCy's similarity model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-yzjdkFQdKQ",
    "outputId": "bc0145c8-1440-4784-be0a-641f1c4a7dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion bear 0.6604732871055603\n",
      "lion cow 0.6303659081459045\n",
      "lion apple 0.5379678010940552\n",
      "lion mango 0.6732673645019531\n",
      "lion spinach 0.4564811885356903\n",
      "bear lion 0.6604732871055603\n",
      "bear bear 1.0\n",
      "bear cow 0.6623415946960449\n",
      "bear apple 0.5358937978744507\n",
      "bear mango 0.5956253409385681\n",
      "bear spinach 0.48093488812446594\n",
      "cow lion 0.6303659081459045\n",
      "cow bear 0.6623415946960449\n",
      "cow cow 1.0\n",
      "cow apple 0.6099163889884949\n",
      "cow mango 0.5889562368392944\n",
      "cow spinach 0.4700290262699127\n",
      "apple lion 0.5379678010940552\n",
      "apple bear 0.5358937978744507\n",
      "apple cow 0.6099163889884949\n",
      "apple apple 1.0\n",
      "apple mango 0.6297526955604553\n",
      "apple spinach 0.38630571961402893\n",
      "mango lion 0.6732673645019531\n",
      "mango bear 0.5956253409385681\n",
      "mango cow 0.5889562368392944\n",
      "mango apple 0.6297526955604553\n",
      "mango mango 1.0\n",
      "mango spinach 0.46731528639793396\n",
      "spinach lion 0.4564811885356903\n",
      "spinach bear 0.48093488812446594\n",
      "spinach cow 0.4700290262699127\n",
      "spinach apple 0.38630571961402893\n",
      "spinach mango 0.46731528639793396\n",
      "spinach spinach 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gill\\AppData\\Local\\Temp\\ipykernel_9992\\786775457.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token11.text, token13.text, token11.similarity(token13))\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokens = nlp(\"lion bear cow apple mango spinach\")\n",
    "for token11 in tokens:\n",
    "    for token13 in tokens:\n",
    "        print(token11.text, token13.text, token11.similarity(token13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A pipeline is a sequence of pipes, or actors on data, that make alterations to the data or extract information from it. In some cases, later pipes require the output from earlier pipes. \n",
    "spaCy is a Python library for Natural Language Processing (NLP). NLP pipelines with spaCy are free and open source. Developers use it to create information extraction and natural language comprehension systems, as in Cython. Use the tool for production, boasting a concise and user-friendly API.\n",
    "\n",
    "Discover the fundamentals of spaCy, such as tokenization, part-of-speech tagging, and named entity identification.\n",
    "\n",
    "Understand spaCy’s text processing architecture, which is efficient and quick, making it appropriate for large-scale NLP jobs.\n",
    "\n",
    "In spaCy, you may explore NLP pipelines and create bespoke pipelines for specific tasks.\n",
    "\n",
    "\n",
    "Explore the advanced capabilities of spaCy, including rule-based matching, syntactic parsing, and entity linking.\n",
    "\n",
    "\n",
    "Learn about the many pre-trained language models available in spaCy and how to utilize them for various NLP applications.\n",
    "Learn named entity recognition (NER) strategies for identifying and categorizing entities in text using spaCy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
